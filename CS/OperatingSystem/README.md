# Operating System

  - [1. 운영체제의 역할](#1-운영체제의-역할)
    - [운영체제란](#운영체제란)
    - [왜 운영체제를 공부하는가](#왜-운영체제를-공부하는가)
    - [멀티 프로세서의 장단점](#멀티-프로세서의-장단점)
    - [Multiprogramming vs Multitasking](#multiprogramming-vs-multitasking)
    - [자원 관리](#자원-관리)
  - [2. 운영체제 구조](2-운영체제-구조)
    - [운영체제 서비스](#운영체제-서비스)
    - [시스템 콜이란](#시스템-콜이란)
    - [응용 프로그램이 운영체제마다 다른이유](#응용-프로그램이-운영체제마다-다른이유)
  - [3. 프로세스](#3-프로세스)
    - [프로세스 개념](#프로세스-개념)
    - [프로세스 제어 블록(PCB)](#프로세스-제어-블록)
    - [프로세스 스케줄링](#프로세스-스케줄링)
    - [프로세스 간 통신](#프로세스-간-통신)
    - [공유 메모리 vs 메시지 전달](#공유-메모리-vs-메시지-전달)
  - [4. 스레드](#4-스레드)
    - [스레드란](#스레드란)
    - [다중 스레드](#다중-스레드)
    - [다중 스레드의 장점](#다중-스레드의-장점)
    - [암묵적 스레딩](#암묵적-스레딩)
  - [5. CPU 스케줄링](#5-cpu-스케줄링)
    - [CPU 스케줄링 개념](#cpu-스케줄링-개념)
    - [CPU 스케줄러](#cpu-스케줄러)
    - [선점 및 비선점 스케줄링](#선점-및-비선점-스케줄링)
    - [디스패처](#디스패처)
    - [스케줄링 알고리즘](#스케줄링-알고리즘)
  - [6. 프로세스 동기화](#6-프로세스-동기화)

    


</br>

* * *
## 1. 운영체제의 역할
#
### 운영체제란
운영체제는 컴퓨터 하드웨어를 관리하는 소프트웨어이다. 즉, 컴퓨터 사용자와 컴퓨터 하드웨어 사이에서 중재자 역할을 수행한다.  
<br>
운영체제의 근본적인 책임은 CPU, 메모리, 입출력 장치, 저장장치 등의 하드웨어 자원들을 프로그램에 할당하는 것이다.  

#
### 왜 운영체제를 공부하는가
모든 코드는 운영체제 위에서 실행되므로, 운영체제 작동방식에 대한 지식은 적절하고 효율적이며 효과적이며 안전한 프로그래밍에 중요하기 때문이다.  

#
### 멀티 프로세서의 장단점
멀티 프로세서의 주요 장점은 처리량 증가이다. 즉, 프로세서 수를 늘리면 더 적은 시간에 더 많은 작업을 수행할 수있다.  
또한 여러 개의 코어를 가지는 하나의 칩은 여러 개의 단일 코어 칩보다 훨씬 적은 전력을 사용하는데, 이는 노트북뿐만 아니라 모바일 장치의 중요한 문제이다.

<br> 
그러나, N개의 프로세서가 사용된다고 해서 속도 향상 비율이 N은 아니다.  
프로세서는 컴퓨터 버스, 메모리, 주변 장치 등을 공유하기 때문에 이러한 경합은 추가 프로세서의 예상 이득을 낮춘다.  
<br> 
<br> 

#
### Multiprogramming vs Multitasking   
다중 프로그래밍은 CPU가 항상 프로세스 한개는 실행할 수있도록 프로그램을 수행하여 CPU 이용률을 높이는 기법이다.  
운영체제는 여러 프로세스를 동시에 메모리에 유지하고, 프로세스 중 하나를 실행한다. 이때 단순히 다른 프로세스로 전환하며 실행하고, 하나의 프로세스가 대기해야 한다면 다른 프로세스로 전환한다.  
<br> 
멀티 태스킹은 다중 프로그래밍의 논리적 확장이다.  
멀티 태스킹 시스템에서 CPU는 여러 프로세스를 전환하며 프로세스를 실행하지만, 전환이 자주 발생하여 사용자에게 빠른 응답 시간을 제공한다.  

동시에 여러 프로세스를 메모리에 유지하려면, 운영체제의 메모리 관리가 필요하다.  
또한 여러 프로세스가 동시에 실행할 준비가 되면 시스템은 다음에 실행할 프로세스를 선택해야 하는데, 이 결정을 내리는 것을 'CPU 스케줄링'이라고 부른다. 

#
### 자원 관리
운영체제는 하드웨어를 관리하는 '자원 관리자'이다. 이때 자원에 속하는 것은 CPU, 메모리, 파일-저장 공간 및 I/O 장치 등이 있다.  

1. 프로세스 관리  
프로그램은 CPU에 의해 명령이 실행되지 않으면 아무것도 할 수없다. 그리고 프로세스는 자기 일을 수행하기 위해 CPU 시간, 메모리, 파일, 그리고 I/O  장치를 포함한 여러 가지 자원을 필요로 한다.  
이러한 자원은 보통 프로세스가 실행되는 동안 할당되고 프로세스가 종료되면 운영체제는 재사용 가능한 자원을 회수한다.  
<br> 
운영체제는 프로세스 관리와 연관해 다음과 같은 책임을 진다.  
(1) 사용자 프로세스와 시스템 프로세스의 생성과 제거  
(2) CPU에 프로세스와 스레드 스케줄링  
(3) 프로세스의 일시 중지와 재수행  
(4) 프로세스 동기화를 위한 기법 제공  
(5)  프로세스 통신을 위한 기법 제공  

2. 메모리 관리  
CPU는 메인 메모리에서만 명령을 적재할 수있으므로, 프로세스를 실행하려면 먼저 메모리에 적재해야한다.  
따라서 메인 메모리는 컴퓨터 시스템의 작동에 중추적인 역할을 할 수있다고 볼 수있다.  
 현대의 컴퓨터는 CPU 이용률과 응답 속도를 개선하기 위해 메모리에 여러개의 프로세스를 유지한다. 그리고 이를 위해서 메모리 기법이 필요하다.  
<br> 
운영체제는 메모리 관리와 연관해 다음과 같은 책임을 진다.  
(1) 메모리의 어느 부분이 현재 사용되고 있으며, 어느 프로세스에 의해 사용되고 있는지를 추적해야 한다.  
(2) 메모리 공간을 할당하고 회수한다.  
(3) 어떤 프로세스를 메모리에 적재하고 제거할 것인가를 결정한다.
3. 파일 시스템 관리  
운영체제는 정보 저장장치에 대한 균일한 논리적 관점을 제공한다.  
대량 저장 매체와 그것을 제어하는 장치를 관리함으로써 파일의 추상적인 개념을 구현하게 된다.  
<br> 
운영체제는 파일 관리를 위해 다음과 같은 일을 담당한다.  
(1) 파일의 생성 및 제거  
(2) 디렉토리 생성 및 제거  
(3) 파일을 보조저장장치로 매핑  

* * * 
## 2. 운영체제 구조
#
### 운영체제 서비스
운영체제는 프로그램 실행 환경을 제공한다.  
운영체제마다 제공하는 서비스는 크게 2가지 목적으로 분류할 수있다.  
1. 사용자에게 도움을 주는 목적
2. 시스템의 효율적인 동작을 위한 목적  

가장 먼저 사용자에게 도움을 주기 위한 목적의 운영체제 서비스는 무엇이 있는지 살펴보자.  
이러한 서비스는 프로그래머가 프로그래밍 작업을 더 쉽게 수행할 수 있도록 한다.
<br> 

1. 사용자 인터페이스  
거의 모든 운영체제는 사용자 인터페이스를 제공한다. 가장 일반적으로 GUI가 사용되고, 모바일 시스템은 터치스크린 인터페이스를 제공하기도 한다.  
2. 프로그램 수행  
시스템 프로그램은 메모리에 적재되어 실행될 수있어야 한다. 
3. 입출력 연산  
수행 중인 프로그램은 입출력을 요구할 수있다. 이러한 입출력에는 파일 혹은 입출력 장치가 연관될 수있다.  
입출력 장치는 사용자들이 직접 제어할 수없고 운영체제가 수단을 제공한다.
4. 파일 시스템 조작  
프로그램은 파일을 읽고 쓸 필요가 있다. 또한 이름에 의해 파일을 생성하고 삭제할 수있고 지정된 파일을 찾을 수있어야 한다.  
운영체제는 특정 성능과 성능 특성을 제공하기 위하여 다양한 파일 시스템을 제공한다.
5. 통신  
한 프로세스가 다른 프로세스와 정보를 교환해야 할 필요가 있는 상황이 존재한다.  
이러한 통신은 '공유 메모리'를 통해 구현될 수도 있고, '메시지 전달' 기법을 사용하여 구현될 수있다.
6. 오류 탐지  
운영체제는 모든 가능한 오류를 항상 의식하고 있어야 한다.  
오류를 의식하는 디버깅 설비는 시스템을 효율적으로 사용할 수있는 사용자와 프로그래머의 능력을 향상시킨다.  

<br> 

다음으로 시스템 자체의 효율적인 동작을 보장하기 위한 운영체제 기능들을 살펴보자.  

1. 자원 할당  
다수의 프로세스나 다수의 작업이 동시에 실행될 때, 그들 각각에 자원을 할당해야 한다. 운영체제는 이를 위해 여러 종류의 자원을 관리하는데, 대표적으로 CPU 스케줄링은 운영체제가 제공하는 서비스이다.
2. 로깅  
운영체제는 어떤 프로그램이 어떤 종류의 컴퓨터 자원을 사용하는지 추적하는 서비스를 제공한다.  
이 사용 통계는 컴퓨팅 서비스를 개선하기 위해 시스템을 재구성하고자 하는 시스템 관리자에게 귀중한 자료가 될 수있다.
3. 보호와 보안  
컴퓨터 시스템에 저장된 정보의 소유자는 그 정보의 사용을 통제하길 원한다. 또한 서로 다른 프로세스가 병행하게 수행될 때, 한 프로세스가 다른 프로세스나 운영체제를 방해해서는 안된다.   
이러한 이유로 운영체제는 컴퓨터 시스템을 보호하는 서비스도 제공한다.
#
### 시스템 콜이란
시스템 콜은 운영체제에 의해 사용 가능하게 된 서비스에 대한 인터페이스이다.
#
### 응용 프로그램이 운영체제마다 다른이유
기본적으로 한 운영체제에서 컴파일된 응용 프로그램은 다른 운영체제에서 실행할 수없다.  
각 운영체제는 시스템 콜 집합을 제공한다. 이 시스템 콜은 응용 프로그램이 사용할 수있도록 운영체제가 제공하는 서비스 집합의 일부이다.  
<br> 
따라서 하나의 API 집합을 호출하도록 설계된 응용 프로그램은 해당 API를 제공하지 않는 운영체제에서는 작동하지 않는다.  

좀더 하드웨어 수준에서 이 문제를 바라보면 다른 어려움이 존재한다.  

- 각 운영체제는 헤더, 명령어 및 변수의 배치를 강제하는 응용 프로그램 형식이 있다. 이러한 구성요소는 명시된 구조 형태로 실행 파일 내의 특정 위치에 있어야 운영체제가 파일을 열고 응용 프로그램을 적재하여 올바르게 실행할 수있음을 의미한다.  
- CPU는 다양한 명령어 집합을 가지며, 해당 명령어가 포함된 응용 프로그램만 올바르게 실행할 수있다.
- 운영체제가 제공하는 시스템 콜은 운영체제마다 다르다.  

* * *
## 3. 프로세스
#
### 프로세스 개념
프로세스는 실행중인 프로그램을 말하며, 현대의 컴퓨팅 시스템에서 작업의 단위를 말한다.  
프로세스의 현재 활동의 상태는 '프로그램 카운터' 값과 '프로세서 레지스터 내용'으로 나타내는데, 프로세스의 메모리 배치는 일반적으로 아래와 같다.  
<br>
![image](https://user-images.githubusercontent.com/76645095/179203467-205f3244-721b-473b-b1d1-c3253fac5050.png)
<br>

- 텍스트 섹션 : 실행 코드
- 데이터 섹션 : 전역 변수
- 힙 섹션 : 프로그램 실행 중에 동적으로 할당되는 메모리
- 스택 섹션 : 함수를 호출할때 임시 데이터 저장장소 

텍스트 및 데이터 섹션의 크기는 고정되기 때문에 프로그램 실행 시간 동안 크기가 변하지 않는다.  
그러나 스택 및 힙 섹션은 프로그램 실행 중에 동적으로 줄어들거나 커질 수있다.  

스택과 힙이 서로의 방향으로 커지기 때문에 운영체제는 이 둘의 영역이 겹치지 않도록 해야한다. 만약 겹친다면 stack overflow, heap overflow를 만날 것이다.  
#
### 프로세스 제어 블록
각 프로세스는 운영체제에서 '프로세스 제어 블록(PCB)'에 의해 표현된다. 아래의 그림은 PCB를 보여주는 그림이다.  

![image](https://user-images.githubusercontent.com/76645095/179204988-f5bc661e-a143-476e-873f-9197dcf2877c.png)  

프로세스 제어 블록은 특정 프로세스와 연관된 여러 정보를 수록하며, 아래와 같은 것들이 포함된다.  
<br>
- 프로세스 상태
- 프로그램 카운터
- CPU 레지스터
- CPU 스케줄링 정보
- 입출력 상태 정보

요약하면 PCB는 약간의 회계 데이터와 함께 프로세스를 시작시키거나 다시 시작시키는 데 필요한 모든 데이터를 위한 저장소의 역할을 한다.  
또한 다중 스레드를 지원하는 현대 시스템에서 PCB는 각 스레드에 관한 정보를 포함하도록 확장되기도 한다.  
#
### 프로세스 스케줄링
기본적으로 각 CPU 코어는 한 번에 하나의 프로세스를 실행할 수있다. 단일 CPU 코어가 있는 시스템의 경우 한 번에 2개 이상의 프로세스가 실행될 수없지만, 다중 코어 시스템은 한 번에 여러 프로세스를 실행할 수있다.  
코어보다 많은 프로세스가 있는 경우 초과 프로세스는 코어가 사용 가능해지고 다시 스케줄될 때까지 기다려야 한다.  
#
#### 스케줄링 큐
프로세스가 시스템에 들어가면 '준비 큐'에 들어가서 준비 상태가 되어 CPU 코어에서 실행되기를 기다리며, 이 큐는 일반적으로 연결 리스트로 저장된다.  
준비 큐 헤더에는 리스트의 첫 번째 PCB에 대한 포인터가 저장되고, 각 PCB에는 준비 큐의 다음 PCB를 가리키는 포인터 필드가 포함된다.  

또한 '대기 큐'라는 것도 존재하는데, 이는 프로세스에 CPU 코어가 할당되었을때, I/O 요청의 완료와 같은 특정 이벤트를 기다리는 큐이다. 프로세스가 스케줄링 큐에 올라가는 흐름은 아래와 같다.  
<br>
새 프로세스는 처음에 준비 큐에 놓인다. 그리고 프로세스는 실행을 위해 선택되거나 기다린다.  
프로세스에 CPU 코어가 할당되고, 실행 상태가 되면 아래와 같은 여러 이벤트 중 하나가 발생할 수있다. 
- 프로세스가 I/O 요청을 공표한 다음 I/O 대기 큐에 놓인다.
- 프로세스는 새 자식 프로세스를 만든 다음 자식의 종료를 기다리는 동안 대기 큐에 놓일 수있다.  
- 인터럽트되어 프로세스가 코어에서 강제로 제거되어 준비 큐로 돌아간다.  


#
#### 문맥 교환(Context Switch)  
인터럽트는 운영체제가 CPU 코어를 현재 작업에서 뺏어 다른 루틴을 실행하는 것이다.  
인터럽트가 발생하면 시스템은 인터럽트 처리가 끝난 후에 '문맥'을 복구할 수 있도록 현재 실행 중인 프로세스의 현재 문맥을 저장할 필요가 있다.  
<br>
이는 결국 프로세스를 중단했다가 재개하는 작업이며, 문맥은 PCB로 표현된다.  
CPU 코어를 다른 프로세스로 교환하려면, 이전의 프로세스의 상태를 보관하고 새로운 프로세스의 보관된 상태를 복구하는 작업이 필요하다.  
이 작업을 '문맥 교환(Context Switch)'라고 부른다.  
<br>
문맥 교환이 진행될 동안 CPU는 아무런 유용한 일을 못하기 때문에 문맥 교환 시간은 순수한 오버헤드가 된다. 

#
#### 프로세스 간 통신
운영체제 내에서 실행되는 프로세스들은 2가지로 분류할 수있다.

- 독립적 프로세스 : 다른 프로세스들과 데이터를 공유하지 않는 프로세스이다.  
- 협력적 프로세스 : 다른 프로세스들에 영향을 주거나 받는 프로세스이다.

프로세스가 협력을 허용하는 환경을 제공하는 데는 몇가지 이유가 있다.
- 정보 공유 : 여러 응용 프로그램이 동일한 정보에 흥미를 느낄 수있으므로, 정보를 병행적으로 접근할 수 있는 환경을 제공해야 한다.
- 계산 가속화 : 특정 태스크를 빨리 실행하고자 한다면, 우리는 태스크를 서브태스크로 나누어 이들 각각이 다른 서브태스크들과 병렬로 실행되게 해야 한다. 
- 모듈성 : 시스템 기능을 별도의 프로세스들 또는 스레드들로 나누어, 모듈식 형태로 시스템을 구성하기를 원할 수 있다.

협력적 프로세스들은 데이터를 교환할 수있는 '프로세스 간 통신(IPC)' 기법이 필요하다.  
IPC를 위한 기본적인 모델로는 아래와 같은 2가지 모델이 있다. 

- 공유 메모리
- 메시지 전달

#
#### 공유 메모리 vs 메시지 전달
공유 메모리가 메시지 전달 기법보다 빠르다.  
메시지 전달 시스템은 신호를 생성하고 전달해야 하는 반면, 공유 메모리는 메모리에 바로 접근해서 사용하면 되기 때문이다.  

만약 공통 데이터를 자주 접근하는 경우 공유 메모리가 효율성이 높고, 분산 시스템에서 네트워크를 통해 다른 프로세스와 통신하는 경우 메시지 전달이 더 적절하다. 
* * * 
## 4. 스레드
#
### 스레드란
스레드는 'CPU 이용의 기본 단위'이다.  
스레드는 스레드 ID, 프로그램 카운터, 레지스터 집합, 스택으로 구성된다. 스레드는 같은 프로세스에 속한 다른 스레드와 코드, 데이터 섹션, 신호와 같은 운영체제 자원들을 공유할 수있다.  
현대의 컴퓨터와 모바일 기기에서 작동하는 거의 모든 소프트웨어 응용들은 다중 스레드를 이용한다.  
<br>
하나의 응용 프로그램이 여러개의 비슷한 작업을 수행할 필요가 있는 상황의 예시로 웹 서버를 떠올려보자.  
하나의 분주한 웹 서버는 여러개의 클라이언트들이 병행하게 접근할 수있다. 만약 웹 서버가 전통적인 단일 스레드 프로세스로 작동한다면, 자신의 단일 프로세스로 한 번에 하나의 클라이언트만 서비스할 수있게 되어 클라이언트는 자신의 요구가 서비스되기까지 매우 긴 시간을 기다려야 한다.  

이 문제를 해결할 수있는 한가지 방법은 서버가 요청을 받아들이는 하나의 프로세스로 동작하게 하는 것이다.  
즉, 서버에게 서비스 요청이 들어오면, 프로세스는 그 요청을 수행할 별도의 프로세스를 생성하는 것이다. 이와 같은 방법은 스레드가 대중화되기 전에는 매우 보편적인 방법이었다.  

하지만, 프로세스 생성 작업은 매우 많은 시간을 소비하고 많은 자원을 필요로 하는 일이다.  
따라서, 새로운 프로세스가 해야 할 일이 기존 프로세스와 동일하다면 굳이 이 많은 오버헤드를 감수해야 할 필요가 없다. 대신 프로세스 안에 여러 스레드를 만들면 더 효율적으로 문제를 해결할 수있다.  

웹 서버가 다중 스레드화 되면, 서버는 클라이언트의 요청을 listen 하는 별도의 스레드를 생성한다. 그러다 클라이언트의 요청이 들어오면 다른 프로세스를 생성하는 것이 아니라, 요청을 서비스할 새로운 스레드를 생성하고 추가적인 요청을 listen 하기 위한 작업을 재개한다.  
#
### 다중 스레드의 장점
다중 스레드 프로그래밍의 이점은 아래의 3가지 큰 부류로 나눌 수있다.  
1. 응답성  
단일 스레드 응용 프로그램은 연산이 완료될 때까지 사용자에게 응답하지 않는다.  
반면 응용 프로그램을 다중 스레드화하면 프로그램의 일부분이 봉쇄되거나, 응용 프로그램이 긴 작업을 수행하더라도 프로그램의 수행이 계속되는 것을 허용함으로써, 사용자에 대한 응답성을 증가시킨다.  

2. 자원 공유  
프로세스는 공유 메모리와 메시지 전달 기법을 통해서만 자원을 공유할 수있다. 그러나 스레드는 자동으로 그들이 속한 프로세스의 자원들과 메모리를 공유한다.  
3. 경제성  
프로세스 생성을 위해 메모리와 자원을 할당하는 것은 비용이 많이 든다. 스레드는 자신이 속한 프로세스의 자원들을 공유하기 때문에 스레드를 생성하고 문맥 교환하는 오버헤드가 더 작다.  
이러한 이유로 새로운 스레드의 생성은 프로세스 생성보다 시간과 메모리를 덜 소비한다.
#
### 암묵적 스레딩
암묵적 스레딩은 병행 및 병렬 프로그램의 설계를 도와주는 한 방법으로, 스레드의 생성과 관리 책임을 개발자가 아닌 컴퓨터가 수행하도록 역할을 떠넘기는 기법이다.  

이 방법을 통해 개발자는 병렬 작업만 식별하면 되고, 스레드 생성 및 관리에 대한 특정 세부사항을 결정할 필요가 없다.  

웹 서버에서 등장하는 '스레드 풀'이라는 개념이 바로 암묵적 스레딩이다. 스레드 풀은 웹 서버가 사용자의 요청을 받을때마다 새로운 스레드를 생성할 수있음에도, 이 생성 시간과 자원을 아끼기 위해 미리 일정량의 스레드를 생성해놓은 것을 말한다.  

* * *
## 5. CPU 스케줄링
#
### CPU 스케줄링 개념
CPU를 프로세스 간에 교환함으로써, 컴퓨터를 보다 생산적으로 만들 수있기 때문에 CPU 스케줄링은 다중 프로그램 운영체제의 기본이다.  
사실 최신 운영체제는 실직적으로 프로세스가 아니라 커널 수준 '스레드'를 스케줄 하는데 이 두 용어는 상호 교환적으로 사용된다.
<br>

코어가 하나인 시스템에서는 한순간에 오직 하나의 프로세스만이 실행될 수있다. 그리고 나머지 프로세스는 CPU의 코어가 가용 상태가 되어 다시 스케줄 될 수 있을 때까지 기다려야 한다.

하나의 프로세스는 전형적으로 어떤 I/O 요청이 완료되기를 기다린다. 
이 대기 시간은 낭비가 되며, CPU가 그저 놀고 있는 시간이다. 

다중 프로그래밍은 CPU 이용률을 최대화하기 위해 CPU가 항상 프로세스를 처리하도록 만든다.  
어느 한 순간에 다수의 프로세스를 메모리에 유지하다가 CPU가 처리하는 어떤 프로세스가 대기해야 할 경우, 운영체제는 CPU를 그 프로세스로부터 회수해 다른 프로세스에 할당한다.  
이러면, 하나의 프로세스가 대기해야 할 때마다 다른 프로세스가 CPU 사용을 양도받을 수있다.

다중 코어 시스템에서도 CPU를 바쁘게 유지하는 이 개념은 시스템의 모든 처리 코어로 확장된다.  
#
### CPU 스케줄러
CPU가 유휴 상태가 될 때마다 운영체제는 '준비 큐'에 있는 프로세스 중에서 하나를 선택해 실행해야 한다.  
이때 선택 절차는 'CPU 스케줄러'에 의해 수행되며, 스케줄러는 실행 준비가 되어 있는 메모리 내의 프로세스 중에서 하나를 선택해 CPU를 할당한다.  
<br>
이때 준비 큐는 반드시 선입선출 방식의 큐가 아니어도 되며 '선입선출 큐', '우선순위 큐', '트리', '연결리스트'로 구현할 수있다.  
준비큐에 있는 모든 프로세스는 CPU에서 실행될 기회를 기다리며 대기하는데, 큐에 있는 레코드들은 일반적으로 프로세스들의 PCB이다.  
<br>

#
### 선점 및 비선점 스케줄링
선점과 비선점 스케줄링은 프로세스가 CPU를 사용하고 있을때, 다른 프로세스가 CPU의 할당을 뺏을 수있는지? 없는지?로 구별한다.  
- 비선점 스케줄링 : Windows, mac, Linux를 포함한 거의 모든 최신 운영체제들은 선점 스케줄링 알고리즘을 사용한다.<br>
비선점 스케줄링은 일단 CPU가 한 프로세스에 할당되면 프로세스가 종료하든지, 또는 대기 상태로 전환할때 까지 CPU를 점유하는 스케줄링 기법이다.
- 선점 스케줄링 : 선점 스케줄링은 다른 프로세스가 이미 CPU를 사용중임에도 불구하고, CPU의 할당을 뺏을 수있는 기법이다. <br>
따라서 데이터가 다수의 프로세스에 의해 공유될 때 경쟁 조건을 초래할 수있고 데이터 일관성이 깨진다는 문제를 가지고 있다. 

#
### 디스패처
디스패처는 CPU 스케줄링 기능에 포함된 요소로 CPU 코어를 CPU 스케줄러가 선택한 프로세스에게 주는 모듈이며, 아래와 같은 작업들을 수행한다.  
- 한 프로세스에서 다른 프로세스로 context switching을 수행
- 사용자 모드로 전환
- 프로그램을 다시 시작하기 위해 사용자 프로그램을 적절한 위치로 이동하는 일

디스패처는 모든 프로세스의 'context switch'시 호출되므로 가능한 빨리 수행되어야 한다.  
디스패처가 하나의 프로세스를 정지하고 다른 프로세스의 수행을 시작하는데까지 소요되는 시간을 '디스패처 지연'이라고 부르며, 아래의 그림과 같다.

<img width="626" alt="image" src="https://user-images.githubusercontent.com/76645095/179911611-065d377c-99ec-4f6b-9735-2a7a7dfa6b14.png">
<br>

### 스케줄링 알고리즘
CPU 스케줄링 알고리즘은 준비 큐에 있는 어느 프로세스에 CPU 코어를 할당할 것인지를 결정하는 문제를 다룬다.  
1. 선입 선처리 스케줄링 (FCFS)  
FCFS는 가장 간단한 CPU 알고리즘으로 CPU를 먼저 요청하는 프로세스가 CPU를 먼저 할당받는다.  
선입 선처리 정책의 구현은 선입선출(FIFO) 큐로 쉽게 관리할 수있으며 프로세스가 준비 큐에 진입하면, 이 프로세스의 PCB을 큐의 끝에 연결한다.  
그리고 CPU가 가용 상태가 되면, 준비 큐의 앞부분에 있는 프로세스에 PCB가 할당된다.  
<br>
하지만, FCFS에서 평균대기 시간은 길어질 수있다. 예를들어 시간 0에 도착한 다음의 프로세스 집합을 보자.
<br>
<br>
<img width="674" alt="image" src="https://user-images.githubusercontent.com/76645095/179913489-9f59bddb-34b3-48f2-9626-af33e63bfbb9.png">
<br>
<br>
프로세스들이 P1, P2, P3 순으로 도착하고, 선입 선처리 순으로 서비스를 받는다면, 아래의 차트와 같은 결과를 얻게 된다. <br>
<br>
<img width="721" alt="image" src="https://user-images.githubusercontent.com/76645095/179913925-10d0b0f5-84be-421b-afe6-cabe736db75e.png">
<br>
<br>
프로세스 P1의 대기 시간은 0밀리초이며, 프로세스 P2는 24밀리초이고, 프로세스 P3은 27밀리초이다.  
그러므로 평균 대기 시간은 (0 + 24 + 27) / 3 = 17 밀리초이다. 
그러나, 프로세스가 P2, P3, P1 순으로 도착하면 결과는 아래와 같다.  
<br>
<br>
<img width="718" alt="image" src="https://user-images.githubusercontent.com/76645095/179914499-cff62581-0f98-4231-bf53-92b4eaf501f4.png">
<br>
평균 대기시간은 이제 (0 + 3 + 6) / 3 = 3밀리초가 된다. 이를통해 알 수있는 것은 FCFS에서 평균대기 시간은 일반적으로 최소가 아니며, 프로세스 CPU 버스트 시간이 크게 변할 경우에는 평균 대기 시간도 상당히 변할 수있다는 것이다.  
<br>
선입 선처리 스케줄링 알고리즘은 기본적으로 CPU가 한 프로세스에 할당되면, 그 프로세스가 종료하든지, I/O 처리를 요구하든지 하여 CPU를 방출할 때까지 CPU를 점유한다. 따라서 '비선점형'이라는 특징을 가지게 된다.  
FCFS 알고리즘은 특히 대화형 시스템에서 문제가 되는데, 그 이유는 대화형 시스템에서는 각 프로세스가 규칙적인 간격으로 CPU의 몫을 얻는 것이 매우 중요하기 때문이다.  
한 프로세스가 지나치게 오랫동안 CPU를 점유하게 허용할 수있는 비선점형에서는 성능의 손해가 매우 크다.  

2. 최단 작업 우선 스케줄링 (SJF)  
또 다른 CPU 스케줄링에 대한 접근 방법으로 '최단 작업 우선(shortest-job-first, SJF)' 알고리즘이 있다.  
이 알고리즘은 각 프로세스에 다음 CPU 버스트 길이를 연관시키며, CPU가 이용 가능해지면, 가장 작은 다음 CPU 버스트를 가진 프로세스에 할당한다.  
<br>
만약 두 프로세스가 동일한 길이의 다음 CPU 버스트를 가지면 순위를 정하기 위해 선입 선처리 스케줄링을 적용한다. 예시로 아래의 프로세스 집합을 고려해보자.  
<br>
![image](https://user-images.githubusercontent.com/76645095/179915981-ba8fd89e-c9e6-479a-a98c-3274a9f82912.png)
<br>
<br>
여기서 SJF 스케줄링을 이용하면, 아래와 같은 차트를 얻을 수있게 된다.  
<br>
<img width="1039" alt="image" src="https://user-images.githubusercontent.com/76645095/179916386-a8ad4df2-4936-4fb0-994c-58a14d6ca5f4.png">
<br>
프로세스 P4의 대기 시간은 0 밀리초이고, P1의 대기 시간은 3밀리초, P3의 대기 시간은 9밀리초, P2의 대기 시간은 16 밀리초이다.  
따라서 평균 대기시간을 계산해보면, (0 + 3 + 9 + 16) / 4 = 7밀리초가 나오게 된다.  
비교를 위해 FCFS 알고리즘을 사용한 경우를 고려해보면, 평균대기 시간은 10.25 밀리초가 된다.  
<br>
SJF 알고리즘은 주어진 프로세스 집합에 대해 최소의 평균 대기 시간을 가진다는 것을 보장하기 때문에 최적임을 증명할 수있다.  
그러나, SJF 알고리즘에서 사용하는 CPU 버스트의 길이를 알 수있는 방법이 없기 때문에 CPU 스케줄링 수준에서는 이를 구현할 수없다.
따라서 이를 구현하기 위해 다음 CPU 버스트 시간을 예측해 사용한다. 일반적으로는 다음 CPU 버스트가 이전의 CPU 버스트와 길이가 비슷하다고 기대한다.  
<br>
SJF 알고리즘은 '선점형' 이거나 '비선점형'일 수있다. 프로세스가 실행되는 동안 새로운 프로세스가 준비큐에 도착하면 CPU는 '선택'을 할 수있다. 이때 선점형은 새로 들어온 프로세스가 현재 실행중인 프로세스보다 CPU 버스트 시간이 짧다면 CPU를 '선점'할 수있고, '비선점'에서는 CPU를 사용하기 시작한 프로세스는 작업이 종료될때까지 CPU를 계속 사용한다.  
<br>
3. 라운드 로빈 스케줄링(Round-Robin)  
라운드 로빈(RR) 스케줄링 알고리즘은 선입 선처리 스케줄링과 유사하지만, '시간 할당량' 이라는 개념이 추가되며 시스템이 프로세스들 사이를 옮겨 다닐 수있도록 선점이 추가된다.  
<br>
준비 큐는 '원형 큐'로 동작하며 CPU는 준비큐를 돌면서 한 번에 한 프로세스에 한 번의 시간 할당량 동안 CPU를 할당한다.  
라운드 로빈 스케줄링을 구현하기 위해 준비큐를 선입선출 큐로 동작하게 만든다.  
<br>
새로운 프로세스들은 준비 큐의 꼬리에 추가되며, CPU 스케줄러는 준비 큐에서 첫 번째 프로세스를 선택해 한 번의 시간 할당량 이후에 인터럽트를 걸도록 '타이머'를 설정한 후, 프로세스를 '디스패치'한다.  
RR 스케줄링 기법을 이해하기 위해 아래의 예시를 살펴보자. 
<br>
<br>
![image](https://user-images.githubusercontent.com/76645095/179921032-2255681e-2989-4290-ba7a-7a82df12d973.png)
<br>
<br>
만약 위와같은 프로세스 집합에 시간 할당량을 4밀리초로 준다면, 프로세스 P1은 처음의 4밀리초를 사용한다.  
이 프로세스는 20밀리초가 더 필요하기 때문에, 이 프로세스는 첫 번째 시간 할당량 이후에 선점되고, CPU는 큐에 있는 다음 프로세스인 P2에 할당된다.  
프로세스 P2는 4밀리초를 필요로 하지 않기 때문에 시간할당량이 끝나기도 전에 종료된다. 그리고 CPU는 이어서 P3에 할당된다.  
P3도 CPU 사용이 끝나면 CPU는 다시 P1에게 할당되며, 라운드 로빈 스케줄의 결과는 아래와 같다.
<br>
<br>
<img width="810" alt="image" src="https://user-images.githubusercontent.com/76645095/179922170-71fbfa3c-d59a-4b67-8731-1fc66138e7f9.png">
<br>
<br>
이 스케줄을 따르는 평균대기 시간을 계산해보면, P1은 6밀리초를 대기하고, P2는 4밀리초, P3는 7밀리초를 기다리기 때문에 평균 대기 시간이 17/3 = 5.66 밀리초가 된다.  
<br>
라운드 로빈 스케줄링 알고리즘에서는 유일하게 실행 가능한 프로세스가 아니라면, 연속적으로 2번 이상의 시간 할당량을 할당받는 프로세스가 생길 수 없다.  
또한 RR 알고리즘은 '선점형'으로 동작하는 것을 알 수있고, '시간 할당량'에 큰 영향을 받는다.  
만약 시간 할당량이 너무 크다면 FCFS 알고리즘과 다른점이 없어지고, 너무 작다면 context switching에 너무 많은 시간이 사용되므로 적절한 시간 할당량을 선정하는 것이 중요하다. 

4. 우선순위 스케줄링(Priority Scheduling)  
각 프로세스에 우선순위를 연관시켜, CPU를 가장 높은 우선순위를 가진 프로세스에 할당시키고, 우선순위가 같은 프로세스의 경우 FCFS로 처리하는 스케줄링 기법이다.  
<br>
예시로 아래와 같은 프로세스 집합이 있다고 가정하자.
<br>
<br>
<img width="787" alt="image" src="https://user-images.githubusercontent.com/76645095/179925170-23cef897-633f-4136-b217-f9723799304b.png">
<br>
<br>
이때 우선순위 스케줄링을 이용해, 스케줄 한 결과를 차트로 나타내면 아래와 같다.
<br>
<br>
<img width="758" alt="image" src="https://user-images.githubusercontent.com/76645095/179925698-bf6fc11d-fff8-4379-b1d0-d76477d49e9d.png">
<br>
<br>
평균대기 시간은 8.2 밀리초가 나오며, 이러한 우선순위 스케줄링에서 사용되는 우선순위는 내부적 또는 외부적으로 정의될 수있다.  
우선순위 스케줄링은 '선점형' 또는 '비선점형'이 될 수있는데, '선점형'일때 발생하는 문제는 '기아 상태'이다.  
<br>
이는 실행 준비가 된 프로세스가 CPU를 기다리는데, 우선순위가 계속 밀려 CPU를 사용하지 못하는 현상을 말한다.  
이를 해결할 수있는 방법으로는 '노화(Aging)'가 있다. 이는 프로세스가 대기하는 시간이 길어질 수록 우선순위를 조금씩 높이는 방법인데, 결국 어떤 프로세스라도 가장 높은 우선순위를 가질 수있게 되므로 기아 문제를 해결할 수있다.

5. 다단계 큐 스케줄링 (Multilevel Queue Scheduling)  
우선순위 큐와 라운드 로빈 스케줄링을 사용할 때 모든 프로세스가 단일 큐에 배치되고, 스케줄러는 우선순위가 가장 높은 프로세스를 선택하여 실행시킬 수 있다.  
이때 큐가 관리되는 방식에 따라 우선순위가 가장 높은 프로세스를 결정하기 위해 O(N) 검색이 필요할 수있다.  
따라서 우선순위마다 별도의 큐를 가지는 것이 프로세스를 찾기에 더 쉬운 방법이 될 때도 있다. 이러한 큐 구조를 '다단계 큐'라고 부르며 아래의 그림에 나타나있다.
<br>
<br>
<img width="663" alt="image" src="https://user-images.githubusercontent.com/76645095/179929641-0190de55-faa7-44d2-8302-c12d9af58b69.png">
<br>
<br>
이 방법은 우선순위 스케줄링이 라운드 로빈과 결합한 경우에도 효과적이다.  
우선순위가 높은 큐에 여러 프로세스가 있는 경우 라운드 로빈 순서로 실행된다.

6. 다단계 피드백 큐 스케줄링 (Multilevel Feedback Queue Scheduling)  
다단계 큐 스케줄링 알고리즘에서 일반적으로 프로세스들은 하나의 큐에 영구적으로 할당된다. 이러한 방식은 융통성이 떨어진다는 문제가 있다.  
이 문제를 해결하기 위해 등장한 것이 '다단계 피드백 큐'이다. 이 스케줄링 알고리즘에서는 프로세스가 큐 사이를 이동하는 것을 허용한다.  
만약 어떤 프로세스가 너무 많은 CPU 시간을 사용한다면, 해당 프로세스를 낮은 우선순위 큐로 이동시키며, 낮은 우선순위 큐에서 너무 오래 기다리는 프로세스는 높은 우선순위 큐로 이동할 수있다.  
<br>
이러한 패러다임 덕분에 다단계 피드백 큐 스케줄링은 '기아 상태'를 예방할 수있다.  
다단계 피드백 큐 스케줄링 알고리즘은 다단계 큐 알고리즘의 장점을 취하고, 기아 상태를 해결할 수있지만, 그만큼 가장 복잡한 스케줄링 기법이다.

* * *
## 6. 프로세스 동기화
#
### 